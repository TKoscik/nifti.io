---
title: "Example Voxelwise Modelling Script"
author: "TRKoscik"
date: "March 20, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## Clear the R environment
This makes sure that variables are not preloaded into the environment, and it ensures that RAM is not being used for things you no longer need
```{r}
rm(list=ls())
gc()
```

### Initialize the R packages that you need for your analysis
```{r}
# Necessary packages
library(nifti.io)
library(doParallel) # depends on R (>= 2.14.0), foreach(>= 1.2.0), iterators(>= 1.0.0), parallel, utils

# Useful packages
library(foreign) # If loading, SPSS, SAS Octave, etc. data
library(tkmisc) # various functions
library(lmerTest) # linear mixed-effects modelling
library(car) # various functions, including Anova with Type III SS
library(R.utils) # necessary for decompressing *.gz files
```

### Load dataframe containing experimental data
```{r}
# reading a *.csv file
pf <- read.csv("/full/path/to/your/data.csv")

# reading an SPSS *.sav file
pf <- read.spss("/full/path/to/your/data.csv", to.data.frame = TRUE)
```

### Specify filepath(s) to brain data
_Brain data must be decompressed, \*.nii only, \*.nii.gz will not work._  

#### Single brain dataset per participant
```{r}
# specify individual paths
data.nii <- c("/full/path/to/brain/file1.nii",
              "/full/path/to/brain/file2.nii",
              "/full/path/to/brain/file3.nii",
              "/full/path/to/brain/file4.nii")

# specifying a single path containing all brain data
data.nii <- list.files("/full/path/to/brain/data/set", pattern="\\.nii$")

# decompressing data for analysis if needed
scratch.dir <- "/full/path/to/directory/to/decompress/data/temporarily"
for (i in 1:length(data.nii)) {
  new.fname <- paste(scratch.dir, sub("\\.gz$", "", basename(data.nii[i])), sep="/")
  gunzip(filename=data.nii[i], dest.name=new.fname, remove=FALSE) # remove = FALSE is important
  data.nii[i] <- new.fname
}
```

#### Multiple brain datasets per participant
```{r}
data.nii <- list() # initialize a list structure to contain each dataset
# specify datasets as individual file paths or single file path
data.nii[[1]] <- c("/full/path/to/brain/file1.nii",
                   "/full/path/to/brain/file2.nii",
                   "/full/path/to/brain/file3.nii",
                   "/full/path/to/brain/file4.nii")
data.nii[[2]] <- list.files("/full/path/to/brain/data/set", pattern="\\.nii$")

# decompressing data for analysis if needed
scratch.dir <- "/full/path/to/directory/to/decompress/data/temporarily"
for (i in 1:length(data.nii)) {
  for (j in 1:length(data.nii[[i]])) {
    new.fname <- paste(scratch.dir, sub("\\.gz$", "", basename(data.nii[[i]][j])), sep="/")
    gunzip(filename=data.nii[[i]][j], dest.name=new.fname, remove=FALSE) # remove = FALSE is important
    data.nii[[i]][j] <- new.fname
  }
}
```

****
# STOP: __IT IS CRITICAL THAT THE SORTING ORDER OF YOUR EXPERIMENTAL DATA AND BRAIN DATA EXACTLY MATCH__
****

### Specify mask for regions on which to run analyses
_Region mask must have the same spacing, orientation, and dimensions as the brain dataset_

#### Single region of interest, e.g., whole brain mask
```{r}
# Region of interest in *.nii file (non-zero values are considered in mask)
data.mask <- "/full/path/to/data/mask.nii"

# OR a 3 column *.csv file with x,y,z coordinates (voxel space)
data.mask <- "/full/path/to/data/mask_coords.csv"

# OR no mask to run all voxels
data.mask <- NULL

# if compressed
new.fname <- paste(scratch.dir, sub("\\.gz$", "", basename(data.mask, sep="/")))
gunzip(filename=data.mask, dest.name=new.fname, remove=FALSE) # remove = FALSE is important
data.mask <- new.fname

```

#### Multiple regions of interest
```{r}
# multi-volume file
data.mask <- "/full/path/to/data/mask.nii"

# OR multiple *.nii files (will include all volumes in each file) and/or */csv files
data.mask <- list()
data.mask[[1]] <- "/full/path/to/data/mask.nii"
data.mask[[2]] <- "/full/path/to/data/mask_coords.csv"
data.mask[[3]] <- NULL # will run remaining voxels

# if compressed
for (i in 1:length(data.mask)) {
  new.fname <- paste(scratch.dir, sub("\\.gz$", "", basename(data.mask[[i]], sep="/")))
  gunzip(filename=data.mask[[i]], dest.name=new.fname, remove=FALSE) # remove = FALSE is important
  data.mask[[i]] <- new.fname
}
```

#### Load coordinate index from ROI mask(s)
__Typically, there is no need to edit this chunk__ 
```{r}
data.idx <- load.mask(data.mask)
n.masks <- length(data.idx)
```


### Specify the location for saving results
```{r}
save.dir <- "/full/path/to/save/results/files"

if (!dir.exists(save.dir)) {
  dir.create(path=save.dir, recursive=TRUE)
}
```

### Load parameters (size and orientation) of desired output  
__Typically, there is no need to edit this chunk__  
```{r}
eg.file <- "/full/path/to/file/with/desired/spacing.nii"
pixdim <- unlist(nii.hdr(eg.file, "pixdim"))
orient <- nii.orient(eg.file)
```

### Specify a prefix to name output files
```{r}
prefix <- "Example"
```

### Specify modelling parameters and formula
```{r}
# Example Linear Model
MODEL <- "lm(DV ~ IV.1 * IV.2, df)"

# Example Linear Mixed-Effects
MODEL <- "lmer(DV ~ IV.1"
```

